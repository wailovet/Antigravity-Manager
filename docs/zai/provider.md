# z.ai provider (Anthropic-compatible passthrough)

## Idea
Support z.ai (GLM) as an optional upstream for **Anthropic-compatible requests** (`/v1/messages`), without applying any Google/Gemini-specific transformations when z.ai is selected.

This keeps compatibility high (request/response shapes stay Anthropic-like) and avoids coupling z.ai traffic to the Google account pool.

## Result
We added an optional “z.ai provider” that:
- Is configured in proxy settings (`proxy.zai.*`).
- Can be enabled/disabled and used via dispatch modes.
- Forwards `/v1/messages` and `/v1/messages/count_tokens` to a z.ai Anthropic-compatible base URL.
- Streams responses back without parsing SSE.

## Configuration
Schema: `src-tauri/src/proxy/config.rs`
- `ZaiConfig` in `src-tauri/src/proxy/config.rs`
- `ZaiDispatchMode` in `src-tauri/src/proxy/config.rs`

Key fields:
- `proxy.zai.enabled`
- `proxy.zai.base_url` (default `https://api.z.ai/api/anthropic`)
- `proxy.zai.api_key` (raw token; a `Bearer ` prefix is also accepted)
- `proxy.zai.dispatch_mode`:
  - `off`
  - `exclusive`
  - `pooled`
  - `fallback`
- `proxy.zai.models` default mapping for `claude-*` request models:
  - `opus`, `sonnet`, `haiku`

## Routing logic
Entry point: [`src-tauri/src/proxy/handlers/claude.rs`](../../src-tauri/src/proxy/handlers/claude.rs)
- `handle_messages(...)` decides whether to route the request to z.ai or to the existing Google-backed flow.
- `handle_count_tokens(...)` uses the same dispatch decision rules (so `fallback`/`pooled` behave consistently).
- `pooled` mode uses round-robin across `(google_accounts + 1)` slots, where slot `0` is z.ai.

### Readiness rules
z.ai is considered **eligible** for routing only when:
- `proxy.zai.enabled=true`
- `proxy.zai.base_url` is non-empty
- `proxy.zai.api_key` is set (raw token; `Bearer <token>` is also accepted)

If `dispatch_mode=exclusive` but the provider is not eligible, the proxy returns an `invalid_request_error` (configuration error) instead of silently falling back to Google.

### Dispatch mode semantics
- `exclusive`: always route Anthropic protocol requests to z.ai.
- `pooled`: z.ai participates as **one extra slot** alongside the Google account pool (roughly `1/(N+1)` selection where `N` is the number of active Google accounts). This is best-effort and not a strict guarantee under retries/concurrency.
- `fallback`: route to z.ai only when the Google pool is unavailable (no active accounts / no available accounts at runtime).

## Upstream implementation
Provider implementation: [`src-tauri/src/proxy/providers/zai_anthropic.rs`](../../src-tauri/src/proxy/providers/zai_anthropic.rs)
- Forwarding is conservative about headers (does not forward the proxy’s own auth key).
- Injects z.ai auth (`Authorization` / `x-api-key`) and forwards the request body as-is.
- Uses the global upstream proxy config when configured.

## OpenCode compatibility notes
OpenCode uses `@ai-sdk/anthropic` and sends top-level fields as Anthropic Messages API payloads.
To keep compatibility across z.ai and non-z.ai routes, the proxy applies the following rules:

### z.ai passthrough (`/v1/messages` routed to z.ai)
- Accepts both `messages[].content` string and array formats (Anthropic standard).
- Normalizes `thinking.budgetTokens` to `thinking.budget_tokens` for upstream compatibility.
- Drops `temperature`, `top_p`, and `effort` (z.ai rejects these with `1210`).
- Preserves unknown top-level fields (e.g. `tool_choice`, `stop_sequences`, `metadata`) while replacing only sanitized `messages`.
- Normalizes streaming errors: z.ai may emit `event: error` without a `type` discriminator. The proxy rewrites these to Anthropic-compatible `{ "type": "error", ... }` and converts `[DONE]` to a `message_stop` event so SDK validators do not fail.

### Google-backed Claude route (when z.ai is not selected)
- `max_tokens` is mapped to `generationConfig.maxOutputTokens`.
- `stop_sequences` is mapped to `generationConfig.stopSequences` (defaults apply when omitted).

## Validation
1) Enable z.ai in the UI (`src/pages/ApiProxy.tsx`) and set `dispatch_mode=exclusive`.
   - UI: [`src/pages/ApiProxy.tsx`](../../src/pages/ApiProxy.tsx)
2) Start the proxy.
3) Send a normal Anthropic request to `POST /v1/messages`.
4) Verify the request is served by z.ai (and Google accounts are not involved for this endpoint in exclusive mode).
